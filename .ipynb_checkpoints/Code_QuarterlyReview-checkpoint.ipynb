{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separately run referrals and claims queries.\n",
    "This file imports the results of those queries, cleans and standardizes each, and merges them for analysis.\n",
    "\n",
    "In addition, we import clinical decision files and use it to \"override\" decisions that were made by analyzing the ROI for specialty & cpt code combination.\n",
    "\n",
    "Finally, several outputs are prepared for reporting purposes, including the calculation of a projected AA approval rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import pyodbc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data directly from SQL databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use referrals.sql, claims.sql, referrals_new.sql, cpt_desc.sql (saved in the same folder as this script) to pull data from relevants servers and databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('referrals_quarterly.sql', 'r') as myfile:\n",
    "    cpts_sql_str=myfile.read().replace('\\n', ' ')\n",
    "\n",
    "cnxn_cpts = pyodbc.connect('DRIVER={SQL Server};SERVER=colo-dwrpt01;DATABASE=IADS_V3')\n",
    "\n",
    "cpts = pd.read_sql(cpts_sql_str, cnxn_cpts)\n",
    "\n",
    "cnxn_cpts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('claims_quarterly.sql', 'r') as myfile:\n",
    "    claims_sql_str=myfile.read().replace('\\n', ' ')\n",
    "\n",
    "cnxn_claims = pyodbc.connect('DRIVER={SQL Server};SERVER=colo-dwrpt01;DATABASE=NATIONAL_ANALYTICS')\n",
    "\n",
    "claims = pd.read_sql(claims_sql_str, cnxn_claims)\n",
    "\n",
    "cnxn_claims.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cpt_desc.sql', 'r') as myfile:\n",
    "    cpt_desc_sql_str=myfile.read().replace('\\n', ' ')\n",
    "\n",
    "cnxn_cpt_desc = pyodbc.connect('DRIVER={SQL Server};SERVER=colo-dwrpt01;DATABASE=IADS_V3')\n",
    "\n",
    "cpt_desc = pd.read_sql(cpt_desc_sql_str, cnxn_cpt_desc)\n",
    "\n",
    "cnxn_cpt_desc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_decisions_current = pd.read_excel('../data/AADictionary_Master.xlsx', sheet_name='Specialty Summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clinical_decisions_20190610 = pd.read_csv('../data/clinical_decision_20190610.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_decisions_current = clinical_decisions_current[['Specialty', 'CPT_Code', 'is_PPL', 'Decision_Source',\n",
    "       'Decision_Maker', 'Reason', 'Decision_Date', 'Decision']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Referrals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all specialties is used repeatedly in the code to loop through specialties and perform certain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all specialties is used repeatedly in the code to loop through \n",
    "# specialties and perform certain tasks.\n",
    "list_o_specs = cpts['Specialty'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update date fields to conform to python datetime\n",
    "cpts['Date_Decision'] = pd.to_datetime(cpts['Date_Decision'])\n",
    "cpts['Date_Received'] = pd.to_datetime(cpts['Date_Received'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensure that the max date from the data is recent, within the last three months\n",
    "if (pd.datetime.now() - cpts['Date_Received'].max()) < timedelta(90):\n",
    "    print(\"Data is near current and runs through {}\".format(cpts['Date_Received'].max()))\n",
    "else:\n",
    "    print(\"Please update the referrals.sql file to pull more current data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (cpts['Date_Received'].max() - cpts['Date_Received'].min()) > timedelta(180):\n",
    "    if (cpts['Date_Received'].max() - cpts['Date_Received'].min()) < timedelta(190):\n",
    "        print(\"Referrals data contains 6 months of data, as expected.\")\n",
    "    else:\n",
    "        print(\"Please update the referrals_quarterly.sql file to pull an entire year of data.\")\n",
    "else:\n",
    "    print(\"Please update the referrals_quarterly.sql file to pull an entire year of data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some specialties need to be broken into Senior and non-commercial \n",
    "## such that we can auto-approve for specific lines of business\n",
    "new_lob = {'COMMERCIAL': '_not_sen',\n",
    "               'SENIOR': '_senior',\n",
    "          'MEDI-CAL': '_not_sen'}\n",
    "cpts['LOB'] = cpts['LOB'].replace(new_lob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this code to check whether recent changes have been captured in the rules\n",
    "clinical_decisions_current[(clinical_decisions_current['Specialty']=='PAIN MANAGEMENT') &\n",
    "                          (clinical_decisions_current['CPT_Code']=='64483')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a list of specialties that will be broken out into LOB for the purposes of AA\n",
    "specs_w_lob_distinct = ['RADIOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through specialties that should be broken by LOB and update the specialty column\n",
    "for spec in list_o_specs:\n",
    "    if spec in specs_w_lob_distinct:\n",
    "        cpts['Specialty'] = np.where(cpts['Specialty']==spec, cpts['Specialty']+cpts['LOB'], cpts['Specialty'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that some specialties are broken into senior and non-senior, need to recreate the list_o_specs\n",
    "list_o_specs = cpts['Specialty'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flag retro statuses with 1 and 0 so they can be removed \n",
    "retro_conditions = [\n",
    " (cpts['status_name'] == 'APPROVED - RETRO REVIEW') |\n",
    " (cpts['status_name'] == 'DENIED - RETRO REVIEW') |\n",
    " (cpts['status_name'] == 'APPROVED - COB RETRO') |\n",
    " (cpts['status_name'] == 'PENDING - RETRO REVIEW') \n",
    "  ]\n",
    "\n",
    "choices = [1]\n",
    "cpts['is_retro'] = np.select(retro_conditions, choices, default=0)\n",
    "\n",
    "## remove retros from list and drop 'is_retro' as it is no longer needed\n",
    "cpts = cpts[cpts['is_retro']==0]\n",
    "cpts.drop(columns='is_retro', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Claims data doesn't come with UNITS & we need to count the number of times a cpt code appears\n",
    "## Here we re-write UNITS to 1.\n",
    "cpts['UNITS'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an auto_approve flag\n",
    "cpts['is_autoapp'] = np.where(cpts['status_name']=='APPROVED - AUTO', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If PPL field is null, assume the referral was not PPL\n",
    "cpts.PPL.fillna(\"N\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a PPL flag\n",
    "cpts['is_PPL'] = np.where(cpts['PPL']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define list of status that should be considered denials\n",
    "den_conditions = [\n",
    " (cpts['status_name'] == 'DENIED - CM') |\n",
    " (cpts['status_name'] == 'DENIED - BENEFIT CARVE OUT') |\n",
    " (cpts['status_name'] == 'DENIED - NOT A COVERED BENEFIT') |\n",
    " (cpts['status_name'] == 'DENIED - APPEAL') |\n",
    " (cpts['status_name'] == 'DENIED - CLINICAL TRIAL/EXP/INV') |\n",
    " (cpts['status_name'] == 'DENIED - TRANSPLANT') |\n",
    " (cpts['status_name'] == 'DENIED - MD') |\n",
    " (cpts['status_name'] == 'DENIED - CM/MD') |\n",
    " (cpts['status_name'] == 'DENIED - REDIRECT OSVN') |\n",
    " (cpts['status_name'] == 'DENIED - TICKLER')\n",
    "  ]\n",
    "\n",
    "## Create a denial flag\n",
    "choices = [1]\n",
    "cpts['is_den'] = np.select(den_conditions, choices, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a \"approved\" flag\n",
    "cpts['is_app'] = np.where(cpts['status_cat']=='APPROVED', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create claims_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some Specialty/CPT code combos appear in referrals data but not in claims data. \n",
    "## In those cases, we look in the claims data across all specialties to find an average\n",
    "## Cost to be applied for that CPT Code.\n",
    "claims_sum = claims.groupby(['CPT_Code'], as_index=False).agg({'avg_hcp_cost': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add variable to designate last 3 vs. prior 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split CPTs data into two parts, one for PRIOR_3 and one for LAST_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = cpts['Date_Received'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = cpts['Date_Received'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_date = min_date + (max_date - min_date)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts['last3'] = np.where(cpts['Date_Received'] >= mid_date, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cpts_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a cpt_code level list of all manually reviewed referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_manual = cpts[cpts['is_autoapp']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_manual.pivot_table(values='HCP_CONNECT_AUTH_NUMBER', index=['is_autoapp', 'is_den'], aggfunc='count', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_of_year_in_data = (max_date - min_date).days / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter the total GA for the department for the year, divide by 2 since we're only looking at 1/2 of the year\n",
    "dept_ga = 6500000 * percent_of_year_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Cost per manually reviewed CPT code\n",
    "\n",
    "ga_cpt = dept_ga / cpts[cpts['is_autoapp']==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the count of manually reviewed cpt codes from each specialty, cpt_code combo \n",
    "cpts_manual = cpts_manual.groupby(['last3', 'Specialty', 'CPT_Code', 'is_PPL'], as_index=False).agg({\n",
    "    'UNITS' : 'count',\n",
    "    'is_den': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To differentiate the count of all units from manual units as we use both in a single\n",
    "## file later\n",
    "cpts_manual.rename(index=str, columns={'UNITS': 'UNITS_man'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the total cost of review any Specialty/cpt_code pair.\n",
    "cpts_manual['cost_to_review'] = cpts_manual['UNITS_man']*ga_cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cptssum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the count, auto-approval rate, and denial rate from each specialty, cpt_code pair\n",
    "cpts2 = cpts.groupby(['last3', 'Specialty', 'CPT_Code', 'is_PPL'], as_index=False).agg({\n",
    "    'UNITS': 'count',\n",
    "    'is_autoapp': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the cost to review (from CPT_manual) into cptssum\n",
    "cpts3 = pd.merge(cpts2, cpts_manual, on=['last3', 'Specialty', 'CPT_Code', 'is_PPL'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge average cost of a cpt code (from claims) into the referrals data\n",
    "cpts4 = pd.merge(cpts3, claims, on=['Specialty', 'CPT_Code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For spec/cpt combos that don't have claims data associated, \n",
    "## use the average of that cpt across specialties\n",
    "## NOTE: the average is not weighted, i.e. each specialties's average contributes equally to\n",
    "## the applied average.\n",
    "cpts_w_claims_fin = pd.merge(cpts4, claims_sum, on='CPT_Code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If there is no average cost from claims at the spec/cpt pair level, fill it with the \n",
    "## average cost for the cpt ACROSS ALL SPECIALTIES\n",
    "cpts_w_claims_fin['avg_hcp_cost_x'] = np.where(cpts_w_claims_fin['avg_hcp_cost_x'].isnull(), \n",
    "                                             cpts_w_claims_fin['avg_hcp_cost_y'],\n",
    "                                             cpts_w_claims_fin['avg_hcp_cost_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unnecessary columns\n",
    "cpts_w_claims_fin.drop(columns=['avg_hcp_cost_y', 'sd_hcp_cost'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename \"_x\" to the normal name - 'avg_hcp_cost'\n",
    "cpts_w_claims_fin.rename(index=str, columns={'avg_hcp_cost_x': 'avg_hcp_cost'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To ensure calculations are defined, replace nulls with 0.\n",
    "cpts_w_claims_fin['UNITS_man'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each spec/cpt code pair, we want to comapre the cost of reviewing the pair with the sum of dollars denied through that review. This is the \"ROI\" of reviewing. In cases where sum of denied dollars is greater than the cost of review, we recommend NOT auto-approving and continue to review. In cases where sum of denied dollars is less than the cost of review then we recommend auto-approving it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the total dollars denied for a pair\n",
    "cpts_w_claims_fin['sum_cost_denied'] = cpts_w_claims_fin['is_den']*cpts_w_claims_fin['UNITS_man']*cpts_w_claims_fin['avg_hcp_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calc ROI for a pair\n",
    "cpts_w_claims_fin['ROI'] = cpts_w_claims_fin['sum_cost_denied']/cpts_w_claims_fin['cost_to_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For groups where we don't know the average cost from 2018, the denominator of ROI is 0, and ROI is undefined. \n",
    "## Update the ROI for those to = 100 so they are NOT included in the dictionaries to auto-approve going forward.\n",
    "cpts_w_claims_fin['ROI'] = np.where(cpts_w_claims_fin['avg_hcp_cost'].isnull(), 100, cpts_w_claims_fin['ROI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For groups that were auto-approved at 100%, the denominator of ROI is 0, and ROI is undefined. \n",
    "## Update the ROI for those to = 0 so they are included in the dictionaries to auto-approve going forward.\n",
    "cpts_w_claims_fin['ROI'] = np.where(cpts_w_claims_fin['ROI'].isnull(), 0.01, cpts_w_claims_fin['ROI'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a flag based on ROI indicated whether the analytics recommend a pair to be auto-approved\n",
    "cpts_w_claims_fin['fin_aa_rec'] = np.where(cpts_w_claims_fin['ROI']<1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QA step - Check that this equals G&A\n",
    "cpts_w_claims_fin['cost_to_review'].sum() == dept_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin_last3 = cpts_w_claims_fin[cpts_w_claims_fin['last3'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin_prior3 = cpts_w_claims_fin[cpts_w_claims_fin['last3'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts10 = pd.merge(cpts_w_claims_fin_last3, cpts_w_claims_fin_prior3, on = ['Specialty', 'CPT_Code', 'is_PPL'], \n",
    "                                   suffixes=('', '_prior3'), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts10.drop(['last3', 'cnt_hcp_cost', 'cost_to_review', 'sum_cost_denied', 'last3_prior3', 'cnt_hcp_cost_prior3',\n",
    "                               'cost_to_review_prior3', 'cnt_hcp_cost_prior3', 'avg_hcp_cost_prior3', 'sum_cost_denied_prior3'], axis=1\n",
    "                              , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Increase in volume\n",
    "cpts10['vol_increase'] = (cpts10['UNITS']/cpts10['UNITS_prior3']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate increase in AA rate\n",
    "cpts10['AA_rate_increase'] = cpts10['is_autoapp']-cpts10['is_autoapp_prior3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate increase in denial rate\n",
    "cpts10['den_rate_increase'] = cpts10['is_den']-cpts10['is_den_prior3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts10 = cpts10.merge(cpt_desc, how='inner', on = 'CPT_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts11 = pd.merge(clinical_decisions_current, cpts10, on=['Specialty', 'CPT_Code', 'is_PPL'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts11['Reason'].fillna('DBA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts11['Reason'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flag retro statuses with 1 and 0 so they can be removed \n",
    "reason_categories = [\n",
    " (cpts11['Reason'] == 'Heavy Cap Vol'),\n",
    " (cpts11['Reason'] == 'Overutilization Concern'),\n",
    " (cpts11['Reason'] == 'Upcoding'),\n",
    " (cpts11['Reason'] == 'Cost Containment'),\n",
    " (cpts11['Reason'] == 'Inappropriate Location'),\n",
    " (cpts11['Reason'] == 'Medical Necessity Review'),\n",
    " (cpts11['Reason'] == 'RNL'),\n",
    " (cpts11['Reason'] == 'Unclassified Drug'),\n",
    " (cpts11['Reason'] == 'Override Pend'),\n",
    " (cpts11['Reason'] == 'DBA'),\n",
    " (cpts11['Reason'] == 'Pend Specialty'),\n",
    " (cpts11['Reason'] == 'Pend EPL'),\n",
    " (cpts11['Reason'] == 'Low Volume') \n",
    "  ]\n",
    "\n",
    "reason_choices = ['M', 'M', 'M', 'do not AA', 'do not AA', 'do not AA', 'do not AA', 'do not AA', 'AA', 'AA', 'do not AA', 'do not AA', 'do not AA']\n",
    "cpts11['reason_cat'] = np.select(reason_categories, reason_choices, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorder the columns to make easier to compare\n",
    "\n",
    "cpts11 = cpts11[['Specialty', 'CPT_Code', 'Name', 'is_PPL', 'Decision_Source',\n",
    "       'Reason', 'reason_cat', 'Decision_Maker', 'Decision_Date', 'Decision', 'UNITS',\n",
    "       'UNITS_prior3', 'vol_increase', 'is_autoapp', 'is_autoapp_prior3',\n",
    "       'AA_rate_increase', 'is_den', 'is_den_prior3', 'den_rate_increase',\n",
    "       'UNITS_man', 'UNITS_man_prior3', 'avg_hcp_cost', 'ROI', 'ROI_prior3',\n",
    "       'fin_aa_rec', 'fin_aa_rec_prior3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts11.sort_values('UNITS', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "quarterly_comparison = '../Data/Outputs/quarterly_comparison.xlsx'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(quarterly_comparison)\n",
    "\n",
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    cpts11.to_excel(quarterly_comparison, index=False, freeze_panes=(1,0))\n",
    "    print('The file did not exist, so created it.')\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
