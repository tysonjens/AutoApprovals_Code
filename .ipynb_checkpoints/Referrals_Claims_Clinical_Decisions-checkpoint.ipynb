{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separately run referrals and claims queries.\n",
    "This file imports the results of those queries, cleans and standardizes each, and merges them for analysis.\n",
    "\n",
    "In addition, we import clinical decision files and use it to \"override\" decisions that were made by analyzing the ROI for specialty & cpt code combination.\n",
    "\n",
    "Finally, several outputs are prepared for reporting purposes, including the calculation of a projected AA approval rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data directly from SQL databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use referrals.sql, claims.sql, referrals_new.sql, cpt_desc.sql (saved in the same folder as this script) to pull data from relevants servers and databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('referrals.sql', 'r') as myfile:\n",
    "    cpts_sql_str=myfile.read().replace('\\n', ' ')\n",
    "\n",
    "cnxn_cpts = pyodbc.connect('DRIVER={SQL Server};SERVER=colo-dwrpt01;DATABASE=IADS_V3')\n",
    "\n",
    "cpts = pd.read_sql(cpts_sql_str, cnxn_cpts)\n",
    "\n",
    "cnxn_cpts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('claims.sql', 'r') as myfile:\n",
    "    claims_sql_str=myfile.read().replace('\\n', ' ')\n",
    "\n",
    "cnxn_claims = pyodbc.connect('DRIVER={SQL Server};SERVER=colo-dwrpt01;DATABASE=NATIONAL_ANALYTICS')\n",
    "\n",
    "claims = pd.read_sql(claims_sql_str, cnxn_claims)\n",
    "\n",
    "cnxn_claims.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step you will import the current version of the clinical decisions.  Note that this is an \"active\" or \"living\" document that is kept up-to-date week-by-week.  As such, you should retrieve the most up-to-date version from the link below before running the next line of code:\n",
    "\\\\is_file\\datashare\\Auto-Approval Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_decisions_current = pd.read_excel('../data/AADictionary_Master.xlsx', sheet_name='Specialty Summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_decisions_current = clinical_decisions_current[['Specialty', 'CPT_Code', 'is_PPL', 'Decision_Source',\n",
    "       'Decision_Maker', 'Reason', 'Decision_Date', 'Decision']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Referrals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all specialties is used repeatedly in the code to loop through specialties and perform certain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all specialties is used repeatedly in the code to loop through \n",
    "# specialties and perform certain tasks.\n",
    "list_o_specs = cpts['Specialty'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update date fields to conform to python datetime\n",
    "cpts['Date_Decision'] = pd.to_datetime(cpts['Date_Decision'])\n",
    "cpts['Date_Received'] = pd.to_datetime(cpts['Date_Received'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Check\n",
    "This code is meant to run on 1 year of referrals data.  This QC check ensures that the sql query above pulled the correct amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensure that the max date from the data is recent, within the last three months\n",
    "if (pd.datetime.now() - cpts['Date_Received'].max()) < timedelta(90):\n",
    "    print(\"Data is near current and runs through {}\".format(cpts['Date_Received'].max()))\n",
    "else:\n",
    "    print(\"Please update the referrals.sql file to pull more current data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (cpts['Date_Received'].max() - cpts['Date_Received'].min()) > timedelta(360):\n",
    "    if (cpts['Date_Received'].max() - cpts['Date_Received'].min()) < timedelta(370):\n",
    "        print(\"Referrals data contains 1 year of data, looks good.\")\n",
    "    else:\n",
    "        print(\"Please update the referrals.sql file to pull an entire year of data.\")\n",
    "else:\n",
    "    print(\"Please update the referrals.sql file to pull an entire year of data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_reasons = ['Pend EPL', 'Pend Specialty', 'Low Volume', np.nan, 'Heavy Cap Vol',\n",
    "       'Medical Necessity Review', 'Needs Review', 'Override Pend',\n",
    "       'Upcoding', 'Cost Containment', 'Overutilization Concern',\n",
    "       'Inappropriate Location', 'RNL', 'Unclassified Drug',\n",
    "       'Sub-Spec Addition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_reasons = list(clinical_decisions_current['Reason'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rsn in current_reasons:\n",
    "    if rsn not in expected_reasons:\n",
    "        print(\"{} is not in the list of expected reasons.\".format(rsn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some specialties need to be broken into Senior and non-commercial \n",
    "## such that we can auto-approve for specific lines of business\n",
    "new_lob = {'COMMERCIAL': '_not_sen',\n",
    "               'SENIOR': '_senior',\n",
    "          'MEDI-CAL': '_not_sen'}\n",
    "cpts['LOB'] = cpts['LOB'].replace(new_lob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a list of specialties that will be broken out into LOB for the purposes of AA\n",
    "specs_w_lob_distinct = ['RADIOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through specialties that should be broken by LOB and update the specialty column\n",
    "for spec in list_o_specs:\n",
    "    if spec in specs_w_lob_distinct:\n",
    "        cpts['Specialty'] = np.where(cpts['Specialty']==spec, cpts['Specialty']+cpts['LOB'], cpts['Specialty'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that some specialties are broken into senior and non-senior, need to recreate the list_o_specs\n",
    "list_o_specs = cpts['Specialty'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append specialties manually that only appear in CCT data\n",
    "list_o_specs.append('HIV/AIDS SPECIALIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flag retro statuses with 1 and 0 so they can be removed \n",
    "retro_conditions = [\n",
    " (cpts['status_name'] == 'APPROVED - RETRO REVIEW') |\n",
    " (cpts['status_name'] == 'DENIED - RETRO REVIEW') |\n",
    " (cpts['status_name'] == 'APPROVED - COB RETRO') |\n",
    " (cpts['status_name'] == 'PENDING - RETRO REVIEW') \n",
    "  ]\n",
    "\n",
    "choices = [1]\n",
    "cpts['is_retro'] = np.select(retro_conditions, choices, default=0)\n",
    "\n",
    "## remove retros from list and drop 'is_retro' as it is no longer needed\n",
    "cpts = cpts[cpts['is_retro']==0]\n",
    "cpts.drop(columns='is_retro', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Claims data doesn't come with UNITS & we need to count the number of times a cpt code appears\n",
    "## Here we re-write UNITS to 1.\n",
    "cpts['UNITS'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an auto_approve flag\n",
    "cpts['is_autoapp'] = np.where(cpts['status_name']=='APPROVED - AUTO', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If PPL field is null, assume the referral was not PPL\n",
    "cpts.PPL.fillna(\"N\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a PPL flag\n",
    "cpts['is_PPL'] = np.where(cpts['PPL']=='Y', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define list of status that should be considered denials\n",
    "den_conditions = [\n",
    " (cpts['status_name'] == 'DENIED - CM') |\n",
    " (cpts['status_name'] == 'DENIED - BENEFIT CARVE OUT') |\n",
    " (cpts['status_name'] == 'DENIED - NOT A COVERED BENEFIT') |\n",
    " (cpts['status_name'] == 'DENIED - APPEAL') |\n",
    " (cpts['status_name'] == 'DENIED - CLINICAL TRIAL/EXP/INV') |\n",
    " (cpts['status_name'] == 'DENIED - TRANSPLANT') |\n",
    " (cpts['status_name'] == 'DENIED - MD') |\n",
    " (cpts['status_name'] == 'DENIED - CM/MD') |\n",
    " (cpts['status_name'] == 'DENIED - REDIRECT OSVN') |\n",
    " (cpts['status_name'] == 'DENIED - TICKLER')\n",
    "  ]\n",
    "\n",
    "## Create a denial flag\n",
    "choices = [1]\n",
    "cpts['is_den'] = np.select(den_conditions, choices, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a \"approved\" flag\n",
    "cpts['is_app'] = np.where(cpts['status_cat']=='APPROVED', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create claims_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some Specialty/CPT code combos appear in referrals data but not in claims data. \n",
    "## In those cases, we look in the claims data across all specialties to find an average\n",
    "## Cost to be applied for that CPT Code.\n",
    "claims_sum = claims.groupby(['CPT_Code'], as_index=False).agg({'avg_hcp_cost': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cpts_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a cpt_code level list of all manually reviewed referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_manual = cpts[cpts['is_autoapp']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter the total GA for the department\n",
    "dept_ga = 6500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Cost per manually reviewed CPT code\n",
    "\n",
    "ga_cpt = dept_ga / cpts[cpts['is_autoapp']==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the count of manually reviewed cpt codes from each specialty, cpt_code combo \n",
    "cpts_manual = cpts_manual.groupby(['Specialty', 'CPT_Code', 'is_PPL'], as_index=False).agg({\n",
    "    'UNITS' : 'count'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To differentiate the count of all units from manual units as we use both in a single\n",
    "## file later\n",
    "cpts_manual.rename(index=str, columns={'UNITS': 'UNITS_man'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the total cost of review any Specialty/cpt_code pair.\n",
    "cpts_manual['cost_to_review'] = cpts_manual['UNITS_man']*ga_cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Check\n",
    "Check to ensure that sum of cost to review column is similar to dept_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (cpts_manual['cost_to_review'].sum() > dept_ga*.95) & (cpts_manual['cost_to_review'].sum() < dept_ga*1.05):\n",
    "    print('Quality Check: Sum of Cost to Review is similar to department G&A.')\n",
    "else:\n",
    "    print('Sum of Cost to Review and Department G&A are more that 5% different, please check.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cptssum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the count, auto-approval rate, and denial rate from each specialty, cpt_code pair\n",
    "cptssum = cpts.groupby(['Specialty', 'CPT_Code', 'is_PPL'], as_index=False).agg({\n",
    "    'UNITS': 'count',\n",
    "    'is_autoapp': 'mean',\n",
    "    'is_den': 'mean',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the cost to review (from CPT_manual) into cptssum\n",
    "cpts_w_claims0 = pd.merge(cptssum, cpts_manual, on=['Specialty', 'CPT_Code', 'is_PPL'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge average cost of a cpt code (from claims) into the referrals data\n",
    "cpts_w_claims1 = pd.merge(cpts_w_claims0, claims, on=['Specialty', 'CPT_Code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For spec/cpt combos that don't have claims data associated, \n",
    "## use the average of that cpt across specialties\n",
    "## NOTE: the average is not weighted, i.e. each specialties's average contributes equally to\n",
    "## the applied average.\n",
    "cpts_w_claims_fin = pd.merge(cpts_w_claims1, claims_sum, on='CPT_Code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If there is no average cost from claims at the spec/cpt pair level, fill it with the \n",
    "## average cost for the cpt ACROSS ALL SPECIALTIES\n",
    "cpts_w_claims_fin['avg_hcp_cost_x'] = np.where(cpts_w_claims_fin['avg_hcp_cost_x'].isnull(), \n",
    "                                             cpts_w_claims_fin['avg_hcp_cost_y'],\n",
    "                                             cpts_w_claims_fin['avg_hcp_cost_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop unnecessary columns\n",
    "cpts_w_claims_fin.drop(columns=['avg_hcp_cost_y', 'sd_hcp_cost'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename \"_x\" to the normal name - 'avg_hcp_cost'\n",
    "cpts_w_claims_fin.rename(index=str, columns={'avg_hcp_cost_x': 'avg_hcp_cost'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To ensure calculations are defined, replace nulls with 0.\n",
    "cpts_w_claims_fin['UNITS_man'] = np.where(cpts_w_claims_fin['UNITS_man'].isnull(), 0, cpts_w_claims_fin['UNITS_man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each spec/cpt code pair, we want to comapre the cost of reviewing the pair with the sum of dollars denied through that review. This is the \"ROI\" of reviewing. In cases where sum of denied dollars is greater than the cost of review, we recommend NOT auto-approving and continue to review. In cases where sum of denied dollars is less than the cost of review then we recommend auto-approving it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the total dollars denied for a pair\n",
    "cpts_w_claims_fin['sum_cost_denied'] = cpts_w_claims_fin['is_den']*cpts_w_claims_fin['UNITS']*cpts_w_claims_fin['avg_hcp_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calc ROI for a pair\n",
    "cpts_w_claims_fin['ROI'] = cpts_w_claims_fin['sum_cost_denied']/cpts_w_claims_fin['cost_to_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For groups where we don't know the average cost from 2018, the denominator of ROI is 0, and ROI is undefined. \n",
    "## Update the ROI for those to = 100 so they are NOT included in the dictionaries to auto-approve going forward.\n",
    "cpts_w_claims_fin['ROI'] = np.where(cpts_w_claims_fin['avg_hcp_cost'].isnull(), 100, cpts_w_claims_fin['ROI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For groups that were auto-approved at 100%, the denominator of ROI is 0, and ROI is undefined. \n",
    "## Update the ROI for those to = 0 so they are included in the dictionaries to auto-approve going forward.\n",
    "cpts_w_claims_fin['ROI'] = np.where(cpts_w_claims_fin['ROI'].isnull(), 0.01, cpts_w_claims_fin['ROI'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a flag based on ROI indicated whether the analytics recommend a pair to be auto-approved\n",
    "cpts_w_claims_fin['fin_aa_rec'] = np.where(cpts_w_claims_fin['ROI']<1, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Additional Auto Approvals when different thresholds are set.\n",
    "## Approach: use \"given\" threshold to determine which CPT codes are \"auto-approve\"-able for each specialty\n",
    "##  - For loop through referrals, return 1 if all CPT codes are on \"auto-approve\"-able list, else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A function that uses cpt_w_claims_fin to generate a dictionary codes to auto-approve.\n",
    "def collect_clinical_decisions(specialty_cpt, list_to_change, spec_list, rsn, new_status=0):\n",
    "    decision_sources = cpts_w_claims_fin['dec_source'].to_list()\n",
    "    overrule_reasons = cpts_w_claims_fin['overrule_rsn'].to_list()\n",
    "    final_decisions = cpts_w_claims_fin['final_decision'].to_list()\n",
    "    for index, row in specialty_cpt.iterrows():\n",
    "        if row['Specialty'] in spec_list:\n",
    "            if row['CPT_Code'] in list_to_change:\n",
    "                decision_sources[index] = 'clinical'\n",
    "                overrule_reasons[index] = rsn\n",
    "                final_decisions[index] = new_status\n",
    "    specialty_cpt['dec_source'] = decision_sources\n",
    "    specialty_cpt['overrule_rsn'] = overrule_reasons\n",
    "    specialty_cpt['final_decision'] = final_decisions\n",
    "    return specialty_cpt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new column in cpt_w_claims_fin that will store decision source.\n",
    "cpts_w_claims_fin['dec_source'] = 'DBA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new column in cpt_w_claims_fin that will store clinical overrule_rsn\n",
    "cpts_w_claims_fin['overrule_rsn'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new column in cpt_w_claims_fin that will store final decision\n",
    "cpts_w_claims_fin['final_decision'] = cpts_w_claims_fin['fin_aa_rec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay Current Clinical Decisions to \"override\" ROI decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in the code we've ingests claims and referrals and for each Spec & CPT code combo we've calculated the ROI of reviewing that combo. In cases where the ROI is above one, we put a temporary decision of pend, and when the ROI is low (below 1) we put a temporary decision of auto-approve.  However, clinical decisions can overturn these ROI decisions. Below we:\n",
    "1. overlay clinical decisions from the AADictionary_Master file\n",
    "2. As a safeguard, we have several portions of code to ensure some of the more broad clinical decisions are in place.  These portions should be in line with AADictionary_Master file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlay current clinical decisions \"on top\" of ROI decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clinical_decisions(cpts_w_claims_fin, clinical_decisions, drop_columns = ['Decision', 'Notes', 'overturned']):\n",
    "    cpts_w_claims_fin = cpts_w_claims_fin.merge(clinical_decisions, how='left', on=['Specialty', 'CPT_Code', 'is_PPL'])\n",
    "    cpts_w_claims_fin['Decision'] = np.where(cpts_w_claims_fin['Decision'].isna(), cpts_w_claims_fin['final_decision'], cpts_w_claims_fin['Decision'])\n",
    "    cpts_w_claims_fin['overrule_rsn'] = np.where(cpts_w_claims_fin['Decision']!=cpts_w_claims_fin['final_decision'], \n",
    "                                    cpts_w_claims_fin['Reason'], cpts_w_claims_fin['overrule_rsn'])\n",
    "    cpts_w_claims_fin['dec_source'] = np.where(cpts_w_claims_fin['Decision']!=cpts_w_claims_fin['final_decision'], \n",
    "                                    'clinical', cpts_w_claims_fin['dec_source'])\n",
    "    cpts_w_claims_fin['final_decision'] = np.where(cpts_w_claims_fin['Decision']!=cpts_w_claims_fin['final_decision'], \n",
    "                                    cpts_w_claims_fin['Decision'], cpts_w_claims_fin['final_decision'])\n",
    "    cpts_w_claims_fin.drop(drop_columns, axis=1, inplace=True)\n",
    "    return cpts_w_claims_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin = add_clinical_decisions(cpts_w_claims_fin, clinical_decisions_current, ['Decision', 'Reason', 'Decision_Date',\n",
    "                                                                                           'Decision_Source', 'Decision_Maker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Pend Specialties categorically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specialties for which the clinical team prefers to ignore the \"decision by analysis\" recommendation and instead\n",
    "## choose a few codes to AA, but mostly the specialty will pend\n",
    "## To ensure that no referrals are auto-approved from it\n",
    "specs_that_should_pend = ['ALLERGY/IMMUNOLOGY',\n",
    " 'PODIATRY',\n",
    " 'PHYSICAL THERAPY/REHAB',\n",
    " 'FACILITY SERVICES',\n",
    " 'GENETICS',\n",
    " 'INTERVENTIONAL RADIOLOGY',\n",
    " 'LABORATROY',\n",
    " 'ONCOLOGY - GYN',\n",
    " 'SURGERY - CARDIAC',\n",
    " 'SURGERY - MAXILLOFACIAL ORAL',\n",
    " 'SURGERY - PLASTIC/RECONSTRUCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec in specs_that_should_pend:\n",
    "    cpts_w_claims_fin['overrule_rsn'] = np.where(cpts_w_claims_fin['Specialty'] == spec, \n",
    "                                    'Soft Pend Specialty', cpts_w_claims_fin['overrule_rsn'])\n",
    "    cpts_w_claims_fin['dec_source'] = np.where(cpts_w_claims_fin['Specialty']==spec, \n",
    "                                    'clinical', cpts_w_claims_fin['dec_source'])\n",
    "    cpts_w_claims_fin['final_decision'] = np.where(cpts_w_claims_fin['Specialty']==spec, \n",
    "                                    0, cpts_w_claims_fin['final_decision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pend codes with fewer than 30 in the past year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pend codes that have volume < 30\n",
    "cpts_w_claims_fin['overrule_rsn'] = np.where(cpts_w_claims_fin['UNITS']<=30, \n",
    "                                    'low volume', cpts_w_claims_fin['overrule_rsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin['dec_source'] = np.where(cpts_w_claims_fin['UNITS']<=30, \n",
    "                                    'rule', cpts_w_claims_fin['dec_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin['final_decision'] = np.where(cpts_w_claims_fin['UNITS']<=30, \n",
    "                                    0, cpts_w_claims_fin['final_decision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard Pend Specialties categorically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specialties that the clinical team wants to pend categorically\n",
    "\n",
    "specs_that_should_pend_hard = ['ACUPUNCTURE', 'ADDICTION MEDICINE', 'ANESTHESIOLOGY',\n",
    "                         'BEHAVIORAL HEALTH', 'CHIROPRACTIC', 'DENTIST', 'DME MAINTENANCE',\n",
    "                         'LICENSED CLIN SOCIAL WORKER', 'MFCC (THERAPIST)', 'NON-CONTRACT UNKWN BILL AREA',\n",
    "                         'NURSE PRACTITIONER', 'NURSING FACILITY - OTHER', 'OPTICIAN',\n",
    "                        'PEDS-DEVELOPMENTAL BEHAVIORAL', 'PSYCHIATRY', 'PSYCHOLOGY', 'SENIOR WELLNESS VISIT',\n",
    "                         'SPORTS MEDICINE', 'SURGERY - ORAL', 'AMBULATORY SURGICAL CENTER', 'AMBULANCE',\n",
    "                         'CUSTODIAL CARE', 'HOME HEALTH', 'INFERTILITY', 'OPTOMETRY', 'PALLIATIVE CARE', 'SLEEP STUDY',\n",
    "                         'SNF - FAC', 'OCCUPATIONAL THERAPY', 'NUCLEAR MEDICINE',\n",
    "                         'PATHOLOGY', 'PHARMACY', 'SURGERY - HAND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec in specs_that_should_pend_hard:\n",
    "    cpts_w_claims_fin['overrule_rsn'] = np.where(cpts_w_claims_fin['Specialty'] == spec, \n",
    "                                    'Hard Pend Specialty', cpts_w_claims_fin['overrule_rsn'])\n",
    "    cpts_w_claims_fin['dec_source'] = np.where(cpts_w_claims_fin['Specialty']==spec, \n",
    "                                    'rule', cpts_w_claims_fin['dec_source'])\n",
    "    cpts_w_claims_fin['final_decision'] = np.where(cpts_w_claims_fin['Specialty']==spec, \n",
    "                                    0, cpts_w_claims_fin['final_decision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pend all EPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pend EPL\n",
    "cpts_w_claims_fin['overrule_rsn'] = np.where(cpts_w_claims_fin['is_PPL']==0, \n",
    "                                    'Pend EPL', cpts_w_claims_fin['overrule_rsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin['dec_source'] = np.where(cpts_w_claims_fin['is_PPL']==0, \n",
    "                                    'rule', cpts_w_claims_fin['dec_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin['final_decision'] = np.where(cpts_w_claims_fin['is_PPL']==0, \n",
    "                                    0, cpts_w_claims_fin['final_decision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AA dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that gathers CPT codes that should be pended and stores them in a dictionary.\n",
    "def create_dict_of_CPT_codes_v3(specialty_cpt, list_o_specs, PPL=1):\n",
    "    spec_dict = {k: [] for k in list_o_specs}\n",
    "    for index, row in specialty_cpt.iterrows():\n",
    "        if row['final_decision'] == 1:\n",
    "            if row['is_PPL'] == PPL:\n",
    "                spec_dict[row['Specialty']].append(row['CPT_Code'])\n",
    "    return spec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensure that the dictionary for EPL is empty, meaning none will auto-approve\n",
    "spec_dict_EPL = {k: [] for k in list_o_specs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict_PPL = create_dict_of_CPT_codes_v3(cpts_w_claims_fin, list_o_specs, PPL=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions of AA Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigns an auto-approve (1) or pend (0) status to each specialty / code group\n",
    "def assign_status(codes, spec_dict_PPL, spec_dict_EPL, list_of_types_pend):\n",
    "    status = list(np.zeros(codes.shape[0]))\n",
    "    specs_list = codes['Specialty'].unique().tolist()\n",
    "    print(len(status))\n",
    "    print(codes.shape[0])\n",
    "    for spec in specs_list:\n",
    "        if spec not in spec_dict_PPL:\n",
    "            spec_dict_PPL[spec] = []\n",
    "    for spec in specs_list:\n",
    "        if spec not in spec_dict_EPL:\n",
    "            spec_dict_EPL[spec] = []\n",
    "    for index, row in codes.iterrows():\n",
    "        if row['is_PPL'] == 1:\n",
    "            if row['CPT_Code'] in spec_dict_PPL[row['Specialty']]:\n",
    "                if row['ref_type'] not in list_of_types_pend:\n",
    "                    status[index] = 1\n",
    "        ##else:\n",
    "          ##  if row['CPT_Code'] in spec_dict_EPL[row['Specialty']]:\n",
    "            ##    status[index] = 0\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_o_types_to_pend = ['INPT ADM', 'EMERGENCY ROOM', 'DAY SURG', 'OOA INPT', \n",
    "                        'SKILLED NURSING', 'OBSERVATION', 'OB OBSERVATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_approve = assign_status(cpts, spec_dict_PPL, \n",
    "                             spec_dict_EPL, list_o_types_to_pend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts['auto_approvable'] = auto_approve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_results = cpts.groupby(['HCP_CONNECT_AUTH_NUMBER'], as_index=False).agg({'auto_approvable': 'mean',\n",
    "                                                                                 'is_den': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_results['aa-yn'] = np.where(refs_results['auto_approvable']==1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_results.drop('auto_approvable', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_results.pivot_table('HCP_CONNECT_AUTH_NUMBER', index='aa-yn', columns='is_den', aggfunc='count', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_results.drop('is_den', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts = cpts.merge(refs_results, how='left', on=['HCP_CONNECT_AUTH_NUMBER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted auto approval rate is {:f}, including a 4% haircut for inability to model facilities'.format(refs_results['aa-yn'].mean()-.04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Specialty Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_new_head = cpts.groupby(['Specialty', 'ref_type', 'HCP_CONNECT_AUTH_NUMBER'], as_index=False).agg({\n",
    "    'UNITS': 'count',\n",
    "    'is_autoapp': 'mean',\n",
    "    'is_PPL': 'mean',\n",
    "    'is_app': 'mean',\n",
    "    'is_den': 'mean',\n",
    "    'aa-yn': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_new_head.pivot_table(values=['is_autoapp', 'aa-yn'], index='Specialty', aggfunc=['count', 'mean']).to_csv('../Data/Outputs/spec_rates.csv',\n",
    "                                                                                                              sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary = pd.read_csv('../Data/Outputs/spec_rates.csv', sep='|', skiprows=3, names=['Specialty',\n",
    "                                                                                             'ref_vol', 'ref_vol2',\n",
    "                                                                                             'new_rate', 'old_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary.drop('ref_vol2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get counts of codes for each specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_code_counts(spec_dict, spec_summary):\n",
    "    counts = []\n",
    "    for index, row in spec_summary.iterrows():\n",
    "        counts.append(len(spec_dict[row['Specialty']]))\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPL_counts = spec_code_counts(spec_dict_PPL, specialty_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary['num_codes']=PPL_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 'denied now approved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_new_head['denied_now_aa'] = refs_new_head['is_den'] * refs_new_head['aa-yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_new_head.pivot_table('denied_now_aa', index='Specialty', aggfunc='sum').to_csv('../Data/Outputs/spec_den_now_aa.csv',\n",
    "                                                                                                      sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_deny_now_aa = pd.read_csv('../Data/Outputs/spec_den_now_aa.csv', sep='|', skiprows=2, names=['Specialty', 'deny_now_aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary = specialty_summary.merge(ss_deny_now_aa, how='inner', on='Specialty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prep cpts_w_claims_fin to merge into cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin_select = cpts_w_claims_fin.drop(['UNITS', 'is_autoapp', 'is_den',\n",
    "       'UNITS_man', 'cost_to_review', 'cnt_hcp_cost',\n",
    "       'sum_cost_denied'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_fin = pd.merge(cpts, cpts_w_claims_fin_select, how='left', on=['Specialty', 'CPT_Code', 'is_PPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_fin['dollars_denied_now_app'] = cpts_w_fin['is_den']*cpts_w_fin['aa-yn']*cpts_w_fin['avg_hcp_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_fin['cost_to_review_bene'] = (1-cpts_w_fin['is_autoapp'])*cpts_w_fin['aa-yn']*ga_cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_fin['cost_to_review_loss'] = cpts_w_fin['is_autoapp']*(1-cpts_w_fin['aa-yn'])*ga_cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_fin['new_denial_bene_est'] = cpts_w_fin['is_autoapp']*(1-cpts_w_fin['aa-yn'])*ga_cpt*cpts_w_fin['ROI']*cpts_w_fin['is_PPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_fin.pivot_table(values=['dollars_denied_now_app', 'cost_to_review_bene', 'cost_to_review_loss',\n",
    "                                  'new_denial_bene_est'], index='Specialty', aggfunc='sum').to_csv('../Data/Outputs/specialty_fins.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_fins = pd.read_csv('../Data/Outputs/specialty_fins.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary = specialty_summary.merge(specialty_fins, how='inner', on='Specialty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary['net_benefit'] = specialty_summary['cost_to_review_bene'] - specialty_summary['cost_to_review_loss'] - specialty_summary['dollars_denied_now_app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary['net_benefit_w_new_den'] = specialty_summary['cost_to_review_bene'] - specialty_summary['cost_to_review_loss'] -specialty_summary['dollars_denied_now_app'] + specialty_summary['new_denial_bene_est']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "spec_summary_filename = '../Data/Outputs/specialty_summary_fin.xlsx'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(spec_summary_filename)\n",
    "\n",
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    specialty_summary.to_excel(spec_summary_filename, index=False, float_format='%.2f',\n",
    "                          header=['Specialty', 'volume', 'new rate', 'old_rate', '# codes in dictionary', 'false positives',\n",
    "                                 'cost to review, benefit', 'cost to review, loss', 'dollars denied, now approved',\n",
    "                                 'new denials, benefit (est)', 'new benefit', 'net benefit, est'], \n",
    "                          freeze_panes=(1,0))\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialty_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin['overrule_rsn'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Detail List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_cpt_w_projected_aa_rate = cpts.groupby(['Specialty', 'CPT_Code', 'is_PPL'], as_index=False).agg({\n",
    "    'aa-yn': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin = cpts_w_claims_fin.merge(spec_cpt_w_projected_aa_rate, how='left', on=['Specialty', 'CPT_Code', 'is_PPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts['UNITS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "spec_cpt_w_projected_aa_rate_fin_filename = '../Data/Outputs/spec_cpt_w_projected_aa_rate.xlsx'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(spec_cpt_w_projected_aa_rate_fin_filename)\n",
    "\n",
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    spec_cpt_w_projected_aa_rate.to_excel(spec_cpt_w_projected_aa_rate_fin_filename, index=False, float_format='%.2f',\n",
    "                          header=['Specialty', 'CPT Code', 'PPL?', 'new rate'], \n",
    "                          freeze_panes=(1,0))\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts.pivot_table('CPT_Code', index='aa-yn', columns='is_den', aggfunc='count', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin.drop(['cnt_hcp_cost'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_desc = pd.read_csv('../Data/cpt_desc_raw.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin = cpts_w_claims_fin.merge(cpt_desc, how='inner', on = 'CPT_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpts_w_claims_fin[cpts_w_claims_fin['Specialty']=='CARDIOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the filename you wish to save the file to\n",
    "cpts_w_claims_fin_filename = '../Data/Outputs/AADictionary_New.xlsx'\n",
    "\n",
    "# Use this function to search for any files which match your filename\n",
    "files_present = os.path.isfile(cpts_w_claims_fin_filename)\n",
    "\n",
    "# if no matching files, write to csv, if there are matching files, print statement\n",
    "if not files_present:\n",
    "    cpts_w_claims_fin.to_excel(cpts_w_claims_fin_filename, index=False, float_format='%.2f',\n",
    "                          header=['Specialty', 'CPT Code', 'PPL?', 'volume', 'old rate', 'denial rate',\n",
    "       'volume, reviewed', 'cost to review', 'avg. cost', 'denied dollars', 'ROI',\n",
    "       'decision by ROI', 'decision source', 'clinical reason', 'final decision', 'new rate',\n",
    "       'CPT desc'], \n",
    "                          freeze_panes=(1,0))\n",
    "else:\n",
    "    print('WARNING: This file already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
